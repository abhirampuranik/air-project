{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "T6cCdGmjq-oj",
        "outputId": "5891692f-91ef-491a-ca40-f5955bc779ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b577a069-a415-4f79-b8e3-f75f1103ea6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Release Year</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Plot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1901</td>\n",
              "      <td>Kansas Saloon Smashers</td>\n",
              "      <td>unknown</td>\n",
              "      <td>bartend work saloon serv drink custom fill ste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1901</td>\n",
              "      <td>Love by the Light of the Moon</td>\n",
              "      <td>unknown</td>\n",
              "      <td>moon paint smile face hang park night young co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1901</td>\n",
              "      <td>The Martyred Presidents</td>\n",
              "      <td>unknown</td>\n",
              "      <td>film minut long compos two shot first girl sit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1901</td>\n",
              "      <td>Terrible Teddy, the Grizzly King</td>\n",
              "      <td>unknown</td>\n",
              "      <td>last six one second consist two shot first sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1902</td>\n",
              "      <td>Jack and the Beanstalk</td>\n",
              "      <td>unknown</td>\n",
              "      <td>earliest known adapt classic fairytal film sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9066</th>\n",
              "      <td>9066</td>\n",
              "      <td>1974</td>\n",
              "      <td>Nightmare Honeymoon</td>\n",
              "      <td>unknown</td>\n",
              "      <td>newlyw david jill webb dack rambo rebecca dian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9067</th>\n",
              "      <td>9067</td>\n",
              "      <td>1974</td>\n",
              "      <td>The Nine Lives of Fritz the Cat</td>\n",
              "      <td>unknown</td>\n",
              "      <td>one nine seven zero fritz cat marri welfar chi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9068</th>\n",
              "      <td>9068</td>\n",
              "      <td>1974</td>\n",
              "      <td>The Parallax View</td>\n",
              "      <td>unknown</td>\n",
              "      <td>tv newswoman lee carter wit assassin president...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9069</th>\n",
              "      <td>9069</td>\n",
              "      <td>1974</td>\n",
              "      <td>Phantom of the Paradise</td>\n",
              "      <td>unknown</td>\n",
              "      <td>stori follow music compos singer winslow leach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9070</th>\n",
              "      <td>9070</td>\n",
              "      <td>1974</td>\n",
              "      <td>Phase IV</td>\n",
              "      <td>unknown</td>\n",
              "      <td>due unknown cosmic event list phase ant underg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9071 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b577a069-a415-4f79-b8e3-f75f1103ea6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b577a069-a415-4f79-b8e3-f75f1103ea6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b577a069-a415-4f79-b8e3-f75f1103ea6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  Release Year                             Title    Genre  \\\n",
              "0              0          1901            Kansas Saloon Smashers  unknown   \n",
              "1              1          1901     Love by the Light of the Moon  unknown   \n",
              "2              2          1901           The Martyred Presidents  unknown   \n",
              "3              3          1901  Terrible Teddy, the Grizzly King  unknown   \n",
              "4              4          1902            Jack and the Beanstalk  unknown   \n",
              "...          ...           ...                               ...      ...   \n",
              "9066        9066          1974               Nightmare Honeymoon  unknown   \n",
              "9067        9067          1974   The Nine Lives of Fritz the Cat  unknown   \n",
              "9068        9068          1974                 The Parallax View  unknown   \n",
              "9069        9069          1974           Phantom of the Paradise  unknown   \n",
              "9070        9070          1974                          Phase IV  unknown   \n",
              "\n",
              "                                                   Plot  \n",
              "0     bartend work saloon serv drink custom fill ste...  \n",
              "1     moon paint smile face hang park night young co...  \n",
              "2     film minut long compos two shot first girl sit...  \n",
              "3     last six one second consist two shot first sho...  \n",
              "4     earliest known adapt classic fairytal film sho...  \n",
              "...                                                 ...  \n",
              "9066  newlyw david jill webb dack rambo rebecca dian...  \n",
              "9067  one nine seven zero fritz cat marri welfar chi...  \n",
              "9068  tv newswoman lee carter wit assassin president...  \n",
              "9069  stori follow music compos singer winslow leach...  \n",
              "9070  due unknown cosmic event list phase ant underg...  \n",
              "\n",
              "[9071 rows x 5 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "df = pd.read_csv(r'preprocessed_dataset.csv')\n",
        "# df.drop(['Director', 'Cast', 'Wiki Page', 'Origin/Ethnicity','Genre','Title','Release Year'], axis=1, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rFtjFMVj07LL",
        "outputId": "2ca70768-bc2e-4554-eba2-e930a3b24e3a"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-be00b4b8aae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-be00b4b8aae7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Plot'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-be00b4b8aae7>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_numbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#remove comma seperately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_apostrophe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_single_characters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-be00b4b8aae7>\u001b[0m in \u001b[0;36mremove_stop_words\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mnew_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "class preproc:\n",
        "  def __init__(self, df):\n",
        "      self.df = df\n",
        "      for i in range(len(self.df['Plot'])):\n",
        "        self.df.at[i,'Plot'] = self.preprocess(self.df.at[i,'Plot'])\n",
        "      \n",
        "\n",
        "  def remove_stop_words(self, data):\n",
        "      stop_words = stopwords.words('english')\n",
        "      words = word_tokenize(str(data))\n",
        "      new_text = \"\"\n",
        "      for w in words:\n",
        "          if w not in stop_words:\n",
        "              new_text = new_text + \" \" + w\n",
        "      return np.char.strip(new_text)\n",
        "\n",
        "  def convert_to_lower_case(self, data):\n",
        "      for i in data:\n",
        "        i = i.lower()\n",
        "      return np.char.lower(data)\n",
        "\n",
        "  def remove_punctuation(self, data):\n",
        "      symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "      for i in range(len(symbols)):\n",
        "          data = np.char.replace(data, symbols[i], ' ')\n",
        "          data = np.char.replace(data, \"  \", \" \")\n",
        "      data = np.char.replace(data, ',', '')\n",
        "      return data\n",
        "\n",
        "  def remove_apostrophe(self, data):\n",
        "      return np.char.replace(data, \"'\", \"\")\n",
        "\n",
        "  def remove_single_characters(self, data):\n",
        "      words = word_tokenize(str(data))\n",
        "      new_text = \"\"\n",
        "      for w in words:\n",
        "          if len(w) > 1:\n",
        "              new_text = new_text + \" \" + w\n",
        "      return np.char.strip(new_text)\n",
        "\n",
        "  def stemming(self, data):\n",
        "      stemmer= PorterStemmer()\n",
        "      \n",
        "      tokens = word_tokenize(str(data))\n",
        "      new_text = \"\"\n",
        "      for w in tokens:\n",
        "          new_text = new_text + \" \" + stemmer.stem(w)\n",
        "      return np.char.strip(new_text)\n",
        "\n",
        "  def convert_numbers(self, data):\n",
        "      data = np.char.replace(data, \"0\", \" zero \")\n",
        "      data = np.char.replace(data, \"1\", \" one \")\n",
        "      data = np.char.replace(data, \"2\", \" two \")\n",
        "      data = np.char.replace(data, \"3\", \" three \")\n",
        "      data = np.char.replace(data, \"4\", \" four \")\n",
        "      data = np.char.replace(data, \"5\", \" five \")\n",
        "      data = np.char.replace(data, \"6\", \" six \")\n",
        "      data = np.char.replace(data, \"7\", \" seven \")\n",
        "      data = np.char.replace(data, \"8\", \" eight \")\n",
        "      data = np.char.replace(data, \"9\", \" nine \")\n",
        "      return data\n",
        "\n",
        "  def preprocess(self, data):     \n",
        "      data = self.convert_to_lower_case(data)\n",
        "      data = self.convert_numbers(data)\n",
        "      data = self.remove_punctuation(data) #remove comma seperately\n",
        "      data = self.remove_stop_words(data)\n",
        "      data = self.remove_apostrophe(data)\n",
        "      data = self.remove_single_characters(data)\n",
        "      data = self.stemming(data)\n",
        "      return str(data)\n",
        "\n",
        "\n",
        "p = preproc(df)\n",
        "df = p.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KbD2em_vWDT",
        "outputId": "4d796c5f-92f8-495b-e7d4-df0f719e941d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abandon' 'abbi' 'abbott' ... 'zero' 'zombi' 'zoo']\n",
            "5000\n",
            "  (0, 2617)\t0.062284020395352906\n",
            "  (0, 1573)\t0.17265324547643557\n",
            "  (0, 3212)\t0.08190593767165132\n",
            "  (0, 201)\t0.09716063362584261\n",
            "  (0, 3445)\t0.1750743300522388\n",
            "  (0, 1627)\t0.10305195539707956\n",
            "  (0, 4867)\t0.11898553994540288\n",
            "  (0, 4261)\t0.20765827165699868\n",
            "  (0, 3708)\t0.1924786393577195\n",
            "  (0, 719)\t0.1473057851333071\n",
            "  (0, 548)\t0.08728938447860295\n",
            "  (0, 2956)\t0.17265324547643557\n",
            "  (0, 4175)\t0.16112285501157836\n",
            "  (0, 341)\t0.12600713279405368\n",
            "  (0, 4966)\t0.1606678540272572\n",
            "  (0, 402)\t0.07898446971133972\n",
            "  (0, 2003)\t0.18346597080434443\n",
            "  (0, 2098)\t0.08678765171067274\n",
            "  (0, 1404)\t0.16112285501157836\n",
            "  (0, 1625)\t0.12161897613947487\n",
            "  (0, 2082)\t0.15869930621616282\n",
            "  (0, 3578)\t0.11128183331852454\n",
            "  (0, 250)\t0.15380910220796712\n",
            "  (0, 2324)\t0.11346224130014844\n",
            "  (0, 618)\t0.15786305235473239\n",
            "  :\t:\n",
            "  (9070, 2684)\t0.14316031053296643\n",
            "  (9070, 2364)\t0.09190833515187184\n",
            "  (9070, 2946)\t0.10207772979093505\n",
            "  (9070, 3344)\t0.13804075231429475\n",
            "  (9070, 2228)\t0.11720554319802046\n",
            "  (9070, 4726)\t0.1212147550346637\n",
            "  (9070, 2698)\t0.10416368193004473\n",
            "  (9070, 1569)\t0.11356751811927612\n",
            "  (9070, 4337)\t0.21079799593887183\n",
            "  (9070, 1243)\t0.10421798685292287\n",
            "  (9070, 1224)\t0.10942572620478795\n",
            "  (9070, 2787)\t0.1232481917461595\n",
            "  (9070, 35)\t0.09270707814609323\n",
            "  (9070, 4477)\t0.2338190640453628\n",
            "  (9070, 903)\t0.1540563671774208\n",
            "  (9070, 1451)\t0.12020390127910054\n",
            "  (9070, 3996)\t0.14777262146261216\n",
            "  (9070, 1699)\t0.07700806260876009\n",
            "  (9070, 1645)\t0.12741103811099322\n",
            "  (9070, 2697)\t0.08413311411585978\n",
            "  (9070, 1731)\t0.0886598181801983\n",
            "  (9070, 4749)\t0.06508933563596464\n",
            "  (9070, 4036)\t0.0722953461328747\n",
            "  (9070, 2396)\t0.10009702774227348\n",
            "  (9070, 402)\t0.0678609650082789\n",
            "tfidf matrix successfully created.\n"
          ]
        }
      ],
      "source": [
        "class tf_idf:\n",
        "  def __init__(self, df):\n",
        "      self.df = df     \n",
        "\n",
        "  def create_tfidf_features(self, col, max_features=5000, max_df=0.95, min_df=2):\n",
        "      \"\"\" Creates a tf-idf matrix for the `corpus` using sklearn. \"\"\"\n",
        "      corpus = df[col].tolist()\n",
        "      tfidf_vectorizor = TfidfVectorizer(decode_error='replace', strip_accents='unicode', analyzer='word',\n",
        "                                        stop_words='english', ngram_range=(1, 1), max_features=max_features,\n",
        "                                        norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
        "                                        max_df=max_df, min_df=min_df)\n",
        "      \n",
        "      X = tfidf_vectorizor.fit_transform(corpus)\n",
        "      arr = tfidf_vectorizor.get_feature_names_out()\n",
        "      print(arr)\n",
        "      print(len(arr))\n",
        "      print(X)\n",
        "      print('tfidf matrix successfully created.')\n",
        "      \n",
        "      return X, tfidf_vectorizor\n",
        "\n",
        "\n",
        "t = tf_idf(df)\n",
        "x, vectorizor = t.create_tfidf_features('Plot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReAwWQNaAiJe"
      },
      "outputs": [],
      "source": [
        "class query_preproc:\n",
        "  def __init__(self, query):\n",
        "    self.query = query\n",
        "    self.query = str(self.preprocess(self.query))\n",
        "\n",
        "  def remove_stop_words(self, data):\n",
        "      stop_words = stopwords.words('english')\n",
        "      words = word_tokenize(str(data))\n",
        "      new_text = \"\"\n",
        "      for w in words:\n",
        "          if w not in stop_words:\n",
        "              new_text = new_text + \" \" + w\n",
        "      return np.char.strip(new_text)\n",
        "\n",
        "  def convert_to_lower_case(self, data):\n",
        "      for i in data:\n",
        "        i = i.lower()\n",
        "      return np.char.lower(data)\n",
        "\n",
        "  def remove_punctuation(self, data):\n",
        "      symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "      for i in range(len(symbols)):\n",
        "          data = np.char.replace(data, symbols[i], ' ')\n",
        "          data = np.char.replace(data, \"  \", \" \")\n",
        "      data = np.char.replace(data, ',', '')\n",
        "      return data\n",
        "\n",
        "  def remove_apostrophe(self, data):\n",
        "      return np.char.replace(data, \"'\", \"\")\n",
        "\n",
        "  def remove_single_characters(self, data):\n",
        "      words = word_tokenize(str(data))\n",
        "      new_text = \"\"\n",
        "      for w in words:\n",
        "          if len(w) > 1:\n",
        "              new_text = new_text + \" \" + w\n",
        "      return np.char.strip(new_text)\n",
        "\n",
        "  def stemming(self, data):\n",
        "      stemmer= PorterStemmer()\n",
        "      \n",
        "      tokens = word_tokenize(str(data))\n",
        "      new_text = \"\"\n",
        "      for w in tokens:\n",
        "          new_text = new_text + \" \" + stemmer.stem(w)\n",
        "      return np.char.strip(new_text)\n",
        "\n",
        "  def convert_numbers(self, data):\n",
        "      data = np.char.replace(data, \"0\", \" zero \")\n",
        "      data = np.char.replace(data, \"1\", \" one \")\n",
        "      data = np.char.replace(data, \"2\", \" two \")\n",
        "      data = np.char.replace(data, \"3\", \" three \")\n",
        "      data = np.char.replace(data, \"4\", \" four \")\n",
        "      data = np.char.replace(data, \"5\", \" five \")\n",
        "      data = np.char.replace(data, \"6\", \" six \")\n",
        "      data = np.char.replace(data, \"7\", \" seven \")\n",
        "      data = np.char.replace(data, \"8\", \" eight \")\n",
        "      data = np.char.replace(data, \"9\", \" nine \")\n",
        "      return data\n",
        "\n",
        "  def preprocess(self, data):     \n",
        "      data = self.convert_to_lower_case(data)\n",
        "      data = self.convert_numbers(data)\n",
        "      data = self.remove_punctuation(data) #remove comma seperately\n",
        "      data = self.remove_stop_words(data)\n",
        "      data = self.remove_apostrophe(data)\n",
        "      data = self.remove_single_characters(data)\n",
        "      data = self.stemming(data)\n",
        "      return str(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "tzDe21Gdz-Jr",
        "outputId": "6a5a8a14-8305-4ab4-e50e-744c9bca93b7"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b84559f0decc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# print(docs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"haunted place\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"funny comedy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"superhero\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"saves people\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Alice follows rabbit hole\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_similarity_ranked_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b84559f0decc>\u001b[0m in \u001b[0;36mquery_similarity_ranked_docs\u001b[0;34m(self, queries)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdocs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msimi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b84559f0decc>\u001b[0m in \u001b[0;36mcalculate_similarity\u001b[0;34m(self, X, vectorizor, query, top_k)\u001b[0m\n\u001b[1;32m      7\u001b[0m       the `query` and `X` (all the documents) and returns the `top_k` similar documents.\"\"\"\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0bab01dd7d52>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mquery_preproc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'query_preproc' object has no attribute 'query'"
          ]
        }
      ],
      "source": [
        "class query:\n",
        "  def __init__(self):\n",
        "      pass\n",
        "\n",
        "  def calculate_similarity(self, X, vectorizor, query, top_k=10):\n",
        "      \"\"\" Vectorizes the `query` via `vectorizor` and calculates the cosine similarity of\n",
        "      the `query` and `X` (all the documents) and returns the `top_k` similar documents.\"\"\"\n",
        "\n",
        "      q = query_preproc(query)\n",
        "      query = q.query\n",
        "\n",
        "      # Vectorize the query to the same length as documents\n",
        "      query_vec = vectorizor.transform(query)\n",
        "      # Compute the cosine similarity between query_vec and all the documents\n",
        "      cosine_similarities = cosine_similarity(X,query_vec).flatten()\n",
        "      # Sort the similar documents from the most similar to less similar and return the indices\n",
        "      most_similar_doc_indices = np.argsort(cosine_similarities, axis=0)[:-top_k-1:-1]\n",
        "      return (most_similar_doc_indices, cosine_similarities)\n",
        "\n",
        "  def show_similar_documents(self, df, cosine_similarities, similar_doc_indices):\n",
        "      counter = 1\n",
        "      for index in similar_doc_indices:\n",
        "          print(\"Index\", index)\n",
        "          print('Top-{}, Similarity = {}'.format(counter, cosine_similarities[index]))\n",
        "          print(df.iloc[index,:])\n",
        "          print()\n",
        "          counter += 1\n",
        "  \n",
        "  def query_similarity_ranked_docs(self, queries):\n",
        "    output = {}\n",
        "    for query in queries:\n",
        "        q = [query]\n",
        "        docs , simi = self.calculate_similarity(x, vectorizor, q, top_k = len(df))\n",
        "        for i in docs:\n",
        "            if(query in output) :\n",
        "                if(simi[i] == 0):\n",
        "                    continue\n",
        "                output[query][i] = simi[i]\n",
        "            else:\n",
        "                output[query] = {}  \n",
        "    return output\n",
        "\n",
        "q = query()\n",
        "# docs , simi = q.calculate_similarity(x, vectorizor, query1, top_k = len(df))\n",
        "# print(docs)\n",
        "queries = [\"haunted place\",\"funny comedy\", \"superhero\",\"saves people\",\"Alice follows rabbit hole\"]\n",
        "output = q.query_similarity_ranked_docs(queries)\n",
        "print(df.iloc[5,:])\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTtT4mMc9_hA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "tfidf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
